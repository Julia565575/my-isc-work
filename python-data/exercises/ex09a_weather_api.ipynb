{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 9a: Weather API\n",
    "\n",
    "## Aim: Use a Weather API to create and graph NetCDF files\n",
    "\n",
    "### Issues covered:\n",
    "\n",
    "- Request and get data from a weather API service\n",
    "- Read and retrieve information from a JSON response\n",
    "- Write contents to a NetCDF file\n",
    "- Read a collection of NetCDF files and plot a time series graph\n",
    "\n",
    "## 1. Let's get data from a web API on the internet\n",
    "\n",
    "We will use the NOAA National Weather Service in the US as our data source:\n",
    "\n",
    "![](https://www.weather.gov/css/images/header.png)\n",
    "\n",
    "The service has a web API that allows you to request forecast data for a given grid point in the USA. Details of the API are documented at:\n",
    "\n",
    "https://www.weather.gov/documentation/services-web-api\n",
    "\n",
    "Use the endpoint `https://api.weather.gov/` as the base URL.\n",
    "\n",
    "Firstly, we want to get a grid ID and based on some latitude/longitude coordinates. To do so we will use the `points/{latitude,longitude}` endpoint of the API.\n",
    "\n",
    "**Choose the latitude and longitude of your favourite US location (this API is US only and in latitude North, longitude East). The extent of the USA is approximately:**\n",
    "- Longitude: -120, -80\n",
    "- Latitude:  30, 48\n",
    "\n",
    "Once you have queried the `points` API you will get back a `grid ID` (`GridId`). The `grid ID`h can be used to get a weather forecast for your location of interest, using the `gridpoints/{grid ID}/{grid co-ordinates}` endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Import the `requests` library which is great for downloading content from external URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can use the requests library to access the web API. Fill in the elipses with the `latitude` (degrees North) and `longitude` (degrees East, so use negative value) of a location in the US. \n",
    "If successful, the response code should be 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.weather.gov/'\n",
    "latitude = 41\n",
    "longitude = -87\n",
    "\n",
    "# Hint: use the requests library to GET from the url: https://api.weather.gov/points/{LAT},{LON}\n",
    "response = requests.get(f'{url}points/{latitude},{longitude}')\n",
    "response.status_code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the requests library, the results from the webAPI can be extracted into in JSON format. A JSON document behaves exactly like a dictionary.\n",
    "\n",
    "Use dictionary indexing to extract the values of the grid ID and the X/Y coordinates:\n",
    "\n",
    "- get `gridID`\n",
    "- get `gridX`\n",
    "- get `gridY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOT\n"
     ]
    }
   ],
   "source": [
    "# hint: you can view the JSON by pasting the URL directly into your browser address bar\n",
    "\n",
    "response = response.json() # java script .json to be able to index into\n",
    "                            # key with a value that is a key .... index further and further\n",
    "\n",
    "gridID = response['properties']['gridId']\n",
    "gridX = response['properties']['gridX']\n",
    "gridY = response['properties']['gridY']\n",
    "\n",
    "print(gridID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your `gridID`, `gridX`, and `gridY`, use the `gridpoints` API endpoint to request a weather forecast for that location. Print the status code.\n",
    "If everything is working, you should get another 200 status code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(f'{url}gridpoints/{gridID}/{gridX},{gridY}')\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you use the JSON response data to get the forecast temperature values? Use dictionary indexing to get the `values` from `temperature` in `properties`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'validTime': '2025-11-21T06:00:00+00:00/PT4H', 'value': 7.777777777777778}, {'validTime': '2025-11-21T10:00:00+00:00/PT4H', 'value': 7.222222222222222}, {'validTime': '2025-11-21T14:00:00+00:00/PT1H', 'value': 7.777777777777778}, {'validTime': '2025-11-21T15:00:00+00:00/PT1H', 'value': 8.88888888888889}, {'validTime': '2025-11-21T16:00:00+00:00/PT1H', 'value': 9.444444444444445}, {'validTime': '2025-11-21T17:00:00+00:00/PT2H', 'value': 10}, {'validTime': '2025-11-21T19:00:00+00:00/PT2H', 'value': 10.555555555555555}, {'validTime': '2025-11-21T21:00:00+00:00/PT1H', 'value': 10}, {'validTime': '2025-11-21T22:00:00+00:00/PT1H', 'value': 9.444444444444445}, {'validTime': '2025-11-21T23:00:00+00:00/PT1H', 'value': 8.333333333333334}, {'validTime': '2025-11-22T00:00:00+00:00/PT1H', 'value': 7.222222222222222}, {'validTime': '2025-11-22T01:00:00+00:00/PT2H', 'value': 6.666666666666667}, {'validTime': '2025-11-22T03:00:00+00:00/PT1H', 'value': 6.111111111111111}, {'validTime': '2025-11-22T04:00:00+00:00/PT2H', 'value': 5.555555555555555}, {'validTime': '2025-11-22T06:00:00+00:00/PT1H', 'value': 5}, {'validTime': '2025-11-22T07:00:00+00:00/PT2H', 'value': 4.444444444444445}, {'validTime': '2025-11-22T09:00:00+00:00/PT1H', 'value': 3.3333333333333335}, {'validTime': '2025-11-22T10:00:00+00:00/PT1H', 'value': 2.2222222222222223}, {'validTime': '2025-11-22T11:00:00+00:00/PT1H', 'value': 1.6666666666666667}, {'validTime': '2025-11-22T12:00:00+00:00/PT2H', 'value': 1.1111111111111112}, {'validTime': '2025-11-22T14:00:00+00:00/PT1H', 'value': 1.6666666666666667}, {'validTime': '2025-11-22T15:00:00+00:00/PT1H', 'value': 4.444444444444445}, {'validTime': '2025-11-22T16:00:00+00:00/PT1H', 'value': 5.555555555555555}, {'validTime': '2025-11-22T17:00:00+00:00/PT1H', 'value': 7.222222222222222}, {'validTime': '2025-11-22T18:00:00+00:00/PT1H', 'value': 8.333333333333334}, {'validTime': '2025-11-22T19:00:00+00:00/PT3H', 'value': 9.444444444444445}, {'validTime': '2025-11-22T22:00:00+00:00/PT1H', 'value': 8.88888888888889}, {'validTime': '2025-11-22T23:00:00+00:00/PT1H', 'value': 7.777777777777778}, {'validTime': '2025-11-23T00:00:00+00:00/PT1H', 'value': 6.666666666666667}, {'validTime': '2025-11-23T01:00:00+00:00/PT1H', 'value': 5.555555555555555}, {'validTime': '2025-11-23T02:00:00+00:00/PT1H', 'value': 5}, {'validTime': '2025-11-23T03:00:00+00:00/PT3H', 'value': 4.444444444444445}, {'validTime': '2025-11-23T06:00:00+00:00/PT1H', 'value': 3.888888888888889}, {'validTime': '2025-11-23T07:00:00+00:00/PT1H', 'value': 3.3333333333333335}, {'validTime': '2025-11-23T08:00:00+00:00/PT1H', 'value': 2.7777777777777777}, {'validTime': '2025-11-23T09:00:00+00:00/PT1H', 'value': 2.2222222222222223}, {'validTime': '2025-11-23T10:00:00+00:00/PT1H', 'value': 1.6666666666666667}, {'validTime': '2025-11-23T11:00:00+00:00/PT2H', 'value': 1.1111111111111112}, {'validTime': '2025-11-23T13:00:00+00:00/PT1H', 'value': 2.2222222222222223}, {'validTime': '2025-11-23T14:00:00+00:00/PT1H', 'value': 3.888888888888889}, {'validTime': '2025-11-23T15:00:00+00:00/PT1H', 'value': 6.111111111111111}, {'validTime': '2025-11-23T16:00:00+00:00/PT1H', 'value': 7.777777777777778}, {'validTime': '2025-11-23T17:00:00+00:00/PT1H', 'value': 10}, {'validTime': '2025-11-23T18:00:00+00:00/PT1H', 'value': 11.11111111111111}, {'validTime': '2025-11-23T19:00:00+00:00/PT1H', 'value': 12.222222222222221}, {'validTime': '2025-11-23T20:00:00+00:00/PT1H', 'value': 12.777777777777779}, {'validTime': '2025-11-23T21:00:00+00:00/PT1H', 'value': 12.222222222222221}, {'validTime': '2025-11-23T22:00:00+00:00/PT1H', 'value': 11.11111111111111}, {'validTime': '2025-11-23T23:00:00+00:00/PT1H', 'value': 9.444444444444445}, {'validTime': '2025-11-24T00:00:00+00:00/PT1H', 'value': 7.777777777777778}, {'validTime': '2025-11-24T01:00:00+00:00/PT1H', 'value': 6.666666666666667}, {'validTime': '2025-11-24T02:00:00+00:00/PT1H', 'value': 5.555555555555555}, {'validTime': '2025-11-24T03:00:00+00:00/PT1H', 'value': 4.444444444444445}, {'validTime': '2025-11-24T04:00:00+00:00/PT1H', 'value': 3.888888888888889}, {'validTime': '2025-11-24T05:00:00+00:00/PT4H', 'value': 3.3333333333333335}, {'validTime': '2025-11-24T09:00:00+00:00/PT4H', 'value': 2.7777777777777777}, {'validTime': '2025-11-24T13:00:00+00:00/PT1H', 'value': 4.444444444444445}, {'validTime': '2025-11-24T14:00:00+00:00/PT1H', 'value': 6.111111111111111}, {'validTime': '2025-11-24T15:00:00+00:00/PT1H', 'value': 7.777777777777778}, {'validTime': '2025-11-24T16:00:00+00:00/PT1H', 'value': 9.444444444444445}, {'validTime': '2025-11-24T17:00:00+00:00/PT1H', 'value': 11.11111111111111}, {'validTime': '2025-11-24T18:00:00+00:00/PT1H', 'value': 12.222222222222221}, {'validTime': '2025-11-24T19:00:00+00:00/PT1H', 'value': 12.777777777777779}, {'validTime': '2025-11-24T20:00:00+00:00/PT2H', 'value': 13.333333333333334}, {'validTime': '2025-11-24T22:00:00+00:00/PT1H', 'value': 12.222222222222221}, {'validTime': '2025-11-24T23:00:00+00:00/PT1H', 'value': 11.666666666666666}, {'validTime': '2025-11-25T00:00:00+00:00/PT1H', 'value': 10.555555555555555}, {'validTime': '2025-11-25T01:00:00+00:00/PT1H', 'value': 10}, {'validTime': '2025-11-25T02:00:00+00:00/PT1H', 'value': 9.444444444444445}, {'validTime': '2025-11-25T03:00:00+00:00/PT4H', 'value': 8.88888888888889}, {'validTime': '2025-11-25T07:00:00+00:00/PT2H', 'value': 9.444444444444445}, {'validTime': '2025-11-25T09:00:00+00:00/PT4H', 'value': 10}, {'validTime': '2025-11-25T13:00:00+00:00/PT1H', 'value': 10.555555555555555}, {'validTime': '2025-11-25T14:00:00+00:00/PT1H', 'value': 11.11111111111111}, {'validTime': '2025-11-25T15:00:00+00:00/PT1H', 'value': 12.222222222222221}, {'validTime': '2025-11-25T16:00:00+00:00/PT2H', 'value': 12.777777777777779}, {'validTime': '2025-11-25T18:00:00+00:00/PT2H', 'value': 13.333333333333334}, {'validTime': '2025-11-25T20:00:00+00:00/PT1H', 'value': 13.88888888888889}, {'validTime': '2025-11-25T21:00:00+00:00/PT1H', 'value': 13.333333333333334}, {'validTime': '2025-11-25T22:00:00+00:00/PT1H', 'value': 12.777777777777779}, {'validTime': '2025-11-25T23:00:00+00:00/PT1H', 'value': 11.11111111111111}, {'validTime': '2025-11-26T00:00:00+00:00/PT1H', 'value': 10}, {'validTime': '2025-11-26T01:00:00+00:00/PT1H', 'value': 9.444444444444445}, {'validTime': '2025-11-26T02:00:00+00:00/PT1H', 'value': 8.88888888888889}, {'validTime': '2025-11-26T03:00:00+00:00/PT1H', 'value': 8.333333333333334}, {'validTime': '2025-11-26T04:00:00+00:00/PT1H', 'value': 7.777777777777778}, {'validTime': '2025-11-26T05:00:00+00:00/PT1H', 'value': 7.222222222222222}, {'validTime': '2025-11-26T06:00:00+00:00/PT1H', 'value': 6.666666666666667}, {'validTime': '2025-11-26T07:00:00+00:00/PT1H', 'value': 5.555555555555555}, {'validTime': '2025-11-26T08:00:00+00:00/PT1H', 'value': 5}, {'validTime': '2025-11-26T09:00:00+00:00/PT1H', 'value': 4.444444444444445}, {'validTime': '2025-11-26T10:00:00+00:00/PT1H', 'value': 3.3333333333333335}, {'validTime': '2025-11-26T11:00:00+00:00/PT1H', 'value': 2.7777777777777777}, {'validTime': '2025-11-26T12:00:00+00:00/PT1H', 'value': 2.2222222222222223}, {'validTime': '2025-11-26T13:00:00+00:00/PT1H', 'value': 2.7777777777777777}, {'validTime': '2025-11-26T14:00:00+00:00/PT1H', 'value': 3.3333333333333335}, {'validTime': '2025-11-26T15:00:00+00:00/PT1H', 'value': 4.444444444444445}, {'validTime': '2025-11-26T16:00:00+00:00/PT1H', 'value': 5}, {'validTime': '2025-11-26T17:00:00+00:00/PT4H', 'value': 5.555555555555555}, {'validTime': '2025-11-26T21:00:00+00:00/PT1H', 'value': 5}, {'validTime': '2025-11-26T22:00:00+00:00/PT1H', 'value': 4.444444444444445}, {'validTime': '2025-11-26T23:00:00+00:00/PT1H', 'value': 3.3333333333333335}, {'validTime': '2025-11-27T00:00:00+00:00/PT1H', 'value': 2.2222222222222223}, {'validTime': '2025-11-27T01:00:00+00:00/PT1H', 'value': 1.1111111111111112}, {'validTime': '2025-11-27T02:00:00+00:00/PT1H', 'value': 0.5555555555555556}, {'validTime': '2025-11-27T03:00:00+00:00/PT1H', 'value': 0}, {'validTime': '2025-11-27T04:00:00+00:00/PT1H', 'value': -0.5555555555555556}, {'validTime': '2025-11-27T05:00:00+00:00/PT1H', 'value': -1.1111111111111112}, {'validTime': '2025-11-27T06:00:00+00:00/PT1H', 'value': -1.6666666666666667}, {'validTime': '2025-11-27T07:00:00+00:00/PT1H', 'value': -2.2222222222222223}, {'validTime': '2025-11-27T08:00:00+00:00/PT1H', 'value': -2.7777777777777777}, {'validTime': '2025-11-27T09:00:00+00:00/PT1H', 'value': -3.3333333333333335}, {'validTime': '2025-11-27T10:00:00+00:00/PT1H', 'value': -3.888888888888889}, {'validTime': '2025-11-27T11:00:00+00:00/PT2H', 'value': -4.444444444444445}, {'validTime': '2025-11-27T13:00:00+00:00/PT1H', 'value': -3.3333333333333335}, {'validTime': '2025-11-27T14:00:00+00:00/PT1H', 'value': -2.2222222222222223}, {'validTime': '2025-11-27T15:00:00+00:00/PT1H', 'value': -1.1111111111111112}, {'validTime': '2025-11-27T16:00:00+00:00/PT1H', 'value': 0}, {'validTime': '2025-11-27T17:00:00+00:00/PT1H', 'value': 0.5555555555555556}, {'validTime': '2025-11-27T18:00:00+00:00/PT1H', 'value': 1.1111111111111112}, {'validTime': '2025-11-27T19:00:00+00:00/PT3H', 'value': 1.6666666666666667}, {'validTime': '2025-11-27T22:00:00+00:00/PT1H', 'value': 1.1111111111111112}, {'validTime': '2025-11-27T23:00:00+00:00/PT1H', 'value': 0}, {'validTime': '2025-11-28T00:00:00+00:00/PT1H', 'value': -1.1111111111111112}, {'validTime': '2025-11-28T01:00:00+00:00/PT1H', 'value': -1.6666666666666667}, {'validTime': '2025-11-28T02:00:00+00:00/PT1H', 'value': -2.2222222222222223}, {'validTime': '2025-11-28T03:00:00+00:00/PT1H', 'value': -2.7777777777777777}, {'validTime': '2025-11-28T04:00:00+00:00/PT2H', 'value': -3.3333333333333335}, {'validTime': '2025-11-28T06:00:00+00:00/PT2H', 'value': -3.888888888888889}, {'validTime': '2025-11-28T08:00:00+00:00/PT1H', 'value': -4.444444444444445}, {'validTime': '2025-11-28T09:00:00+00:00/PT1H', 'value': -5}, {'validTime': '2025-11-28T10:00:00+00:00/PT1H', 'value': -5.555555555555555}, {'validTime': '2025-11-28T11:00:00+00:00/PT2H', 'value': -6.111111111111111}, {'validTime': '2025-11-28T13:00:00+00:00/PT1H', 'value': -5.555555555555555}, {'validTime': '2025-11-28T14:00:00+00:00/PT1H', 'value': -4.444444444444445}, {'validTime': '2025-11-28T15:00:00+00:00/PT1H', 'value': -2.7777777777777777}, {'validTime': '2025-11-28T16:00:00+00:00/PT1H', 'value': -1.6666666666666667}, {'validTime': '2025-11-28T17:00:00+00:00/PT1H', 'value': -1.1111111111111112}, {'validTime': '2025-11-28T18:00:00+00:00/PT1H', 'value': -0.5555555555555556}, {'validTime': '2025-11-28T19:00:00+00:00/PT3H', 'value': 0}, {'validTime': '2025-11-28T22:00:00+00:00/PT1H', 'value': -1.1111111111111112}, {'validTime': '2025-11-28T23:00:00+00:00/PT1H', 'value': -1.6666666666666667}, {'validTime': '2025-11-29T00:00:00+00:00/PT1H', 'value': -2.7777777777777777}]\n"
     ]
    }
   ],
   "source": [
    "data = response.json()\n",
    "forecast = data['properties']['temperature']['values']\n",
    "print(forecast)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code extracts the coordinates of the grid box you have chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = data['geometry']['coordinates'][0][0]\n",
    "x = coords[1]\n",
    "y = coords[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let's format that data and write it to NetCDF\n",
    "\n",
    "### Formatting the data\n",
    "\n",
    "First, format your forecast data to get the datetime and air temperature as separate\n",
    "lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through your `forecast` values and get the temperatures (`value`) and datetimes (`validTime`) into a list.\n",
    "`forecast` is a list of dictionaries, where each dictionary is of one time instance.\n",
    "Fill in the ellipses to format each `validTime` string to a python `datetime` object and assign and set to the variable `date`. Get each `value` and assign to the variable `temp`. These values will then be appended to the `temps` and `timeseries` lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the datetime module to convert the times from the data to a datetime object.\n",
    "# Hint: look at the validTime string and see how you can turn the string to datetime\n",
    "# using strptime, the format of the datetime is: '%Y-%m-%dT%H:%M:%Sz'.\n",
    "#from datetime import datetime\n",
    "\n",
    "timeseries = []\n",
    "temps = []\n",
    "\n",
    "for item in forecast:\n",
    "    ...\n",
    "    temp = item['value']\n",
    "    date = item['validTime']\n",
    "    #date_split = date_string.split('P',1)\n",
    "    date = dt.strptime(date.split('/')[0], '%Y-%m-%dT%H:%M:%S%z')\n",
    "    #date_split.Datetime\n",
    "    #print(date_split)\n",
    "    timeseries.append(date)\n",
    "    temps.append(temp)\n",
    "\n",
    "    # date = item['validTime']\n",
    "    # date = dt.strptime(date.split('/')[0], '%Y-%m-%dT%H:%M:%S%z')\n",
    "    # timeseries.append(date)\n",
    "    \n",
    "    # temp = item['value']\n",
    "    # temps.append(temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the `timeseries` list and convert it to relative time in seconds from the start of the timeseries. When using NetCDF and the CF Metadata Conventions time is stored as an offset from a base time rather than an absolute times.\n",
    "\n",
    "If you are stuck, take look at the 'Time series' slide in the [logging data from serial ports](https://github.com/ncasuk/ncas-isc/raw/68abbfd3a573e576c32fc127fafc874bfff98b1e/python/presentations/logging-data-from-serial-ports/LDFSP_Slides.pdf) presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_time = timeseries[0]\n",
    "time_values = []\n",
    "\n",
    "for t in timeseries:\n",
    "    ...#t-base_time\n",
    "    value = t-base_time\n",
    "    #print(type(value))\n",
    "    ts = value.total_seconds()\n",
    "    time_values.append(ts)\n",
    "\n",
    "time_units = \"seconds since \" + base_time.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert the `temps` list from degrees C to Kelvin. As per the CF Conventions, the canonical units for Air Temperature is K. Create a new list, called `temp_values`, which is the temperature in Kelvin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_values = []\n",
    "\n",
    "for temp_C in temps:\n",
    "    temp_K= temp_C+273.15\n",
    "    temp_values.append(temp_K)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a netCDF4 Dataset and write the contents to a file\n",
    "\n",
    "Import the `Dataset` class from the `netCDF4` library. You can go on to create an *instance* of this class which will contain:\n",
    "- variables\n",
    "- coordinate variables\n",
    "- dimensions\n",
    "- global attributes\n",
    "\n",
    "When you create the instance of `Dataset`, you will give it a file name which will be written to when you close the `Dataset`.\n",
    "\n",
    "Also import `numpy` as `np`. This will be used to construct the data arrays from the existing lists that currently hold the weather data and coordinate information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick aside, let's make sure we have a `DATA_DIR` to write to\n",
    "\n",
    "Since this is a group exercise, everyone should be writing to the same output directory. Let's set some python variables that can be used below:\n",
    "1. `USER` - used in the output file names to ensure every NetCDF file is unique.\n",
    "2. `HOME_DIR` - your `$HOME` directory\n",
    "2. `MY_DATA_DIR` - the directory where you will write your NetCDF file.\n",
    "3. `GROUP_DATA_DIR` - the directory where all the NetCDF files will eventually be collected/available.\n",
    "\n",
    "Since `GROUP_DATA_DIR` is not writeable directly from the Notebook Service, we have set up a job to replicate files from `MY_DATA_DIR` to `GROUP_DATA_DIR` (which runs once per minute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "USER = os.environ[\"JUPYTERHUB_USER\"]\n",
    "\n",
    "HOME_DIR = f\"/home/users/{USER}\"\n",
    "MY_DATA_DIR = os.path.join(HOME_DIR, \"weather-api-outputs\")\n",
    "\n",
    "# Create MY_DATA_DIR if it doesn't exist\n",
    "if not os.path.isdir(MY_DATA_DIR):\n",
    "    os.mkdir(MY_DATA_DIR)\n",
    "\n",
    "# All NetCDF will be automatically copied here (once per minute)\n",
    "GROUP_DATA_DIR = \"/gws/pw/j07/workshop/weather-api-data\"\n",
    "\n",
    "# The output file will initially be written to your HOME_DIR (then you will move\n",
    "# it when complete)\n",
    "filename = f\"{gridID}-{USER}-temps.nc\"\n",
    "outfile = f\"{HOME_DIR}/{filename}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to our NetCDF file\n",
    "\n",
    "Create the output file, as a `netCDF4 Dataset` instance, using the `outfile` defined above.\n",
    "\n",
    "If you need help, have a look at the 'Create the NetCDF dimensions & variables' slide in the [logging data from serial ports](https://github.com/ncasuk/ncas-isc/raw/68abbfd3a573e576c32fc127fafc874bfff98b1e/python/presentations/logging-data-from-serial-ports/LDFSP_Slides.pdf) presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(outfile,'w', format='NETCDF4_CLASSIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start by defining some dimensions\n",
    "\n",
    "Create NetCDF *dimensions*:\n",
    "- `time_dim`: *unlimited* length\n",
    "- `lat_dim`: length 1\n",
    "- `lon_dim`: length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'netCDF4._netCDF4.Dimension' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# time_dim = dataset.createDimension('time', None) # None means \"UNLIMITED\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# lat_dim = dataset.createDimension('lat', 1)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# lon_dim = dataset.createDimension('lon', 1)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtime_dim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'netCDF4._netCDF4.Dimension' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# time_dim = dataset.createDimension('time', None) # None means \"UNLIMITED\"\n",
    "# lat_dim = dataset.createDimension('lat', 1)\n",
    "# lon_dim = dataset.createDimension('lon', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now define the coordinate variables and then temperature variable\n",
    "\n",
    "Create the `time` *variable* with the following properties:\n",
    "- type: numpy float (`np.float64`)\n",
    "- variable id: `time`\n",
    "- dimensions: (`time`,)\n",
    "- set the array using the `time_values` list\n",
    "- `units`: `time_units` defined earlier\n",
    "- `standard_name`: `time`\n",
    "- `calendar`: `standard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_var = dataset.createVariable('time', np.float64, ('time',))\n",
    "time_var[:] = time_values\n",
    "time_var.units = time_units\n",
    "time_var.standard_name = 'time'\n",
    "time_var.calendar = 'standard'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `lat` *variable* with the following properties:\n",
    "- type: numpy float (`np.float64`)\n",
    "- variable id: `lat`\n",
    "- dimensions: (`lat`,)\n",
    "- set the array of length 1 using the `gridY` value\n",
    "- `units`: `degrees_north`\n",
    "- `standard_name`: `latitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_var = dataset.createVariable('lat', np.float64, ('lat',))\n",
    "lat_var[:] = [gridY]\n",
    "lat_var.units = 'degree_north'\n",
    "lat_var.standard_name = 'latitude'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `lon` *variable* with the following properties:\n",
    "- type: numpy float (`np.float64`)\n",
    "- variable id: `lon`\n",
    "- dimensions: (`lon`,)\n",
    "- set the array of length 1 using the `gridX` value\n",
    "- `units`: `degrees_east`\n",
    "- `standard_name`: `longitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "NetCDF: Attribute not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# lon_var = dataset.createVariable('lon', np.float64, ('lon',))\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# lon_var[:] = [gridX]\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# lon_var.units = 'degree_east'\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# lon_var.standard_name = 'longitude'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlon_var\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvar_id\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:5030\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Variable.__getattr__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:4752\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Variable.getncattr\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:1667\u001b[39m, in \u001b[36mnetCDF4._netCDF4._get_att\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2164\u001b[39m, in \u001b[36mnetCDF4._netCDF4._ensure_nc_success\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: NetCDF: Attribute not found"
     ]
    }
   ],
   "source": [
    "lon_var = dataset.createVariable('lon', np.float64, ('lon',))\n",
    "lon_var[:] = [gridX]\n",
    "lon_var.units = 'degree_east'\n",
    "lon_var.standard_name = 'longitude'\n",
    "# print(lon_var.var_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `temp` *variable* with the following properties:\n",
    "- type: numpy float (`np.float64`)\n",
    "- variable id: `temp`\n",
    "- dimensions: (`time`,)\n",
    "- set the array using the `temp_values` list\n",
    "- `long_name`: `air temperature (K)`\n",
    "- `units`: `K`\n",
    "- `standard_name`: `air_temperature`\n",
    "- `coordinates`: `lon lat` - to relate the longitude and latitude to this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: String match to name in use: (variable 'temp', group '/')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m temp_var = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreateVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtemp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m temp_var[:] = temp_values\n\u001b[32m      3\u001b[39m temp_var.var_id = \u001b[33m'\u001b[39m\u001b[33mtemp\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:3007\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Dataset.createVariable\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:4231\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Variable.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2164\u001b[39m, in \u001b[36mnetCDF4._netCDF4._ensure_nc_success\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: NetCDF: String match to name in use: (variable 'temp', group '/')"
     ]
    }
   ],
   "source": [
    "temp_var = dataset.createVariable('temp', np.float64, ('time',))\n",
    "temp_var[:] = temp_values\n",
    "temp_var.var_id = 'temp'\n",
    "temp_var.long_name = 'air temperature (K)'\n",
    "temp_var.units = 'K'\n",
    "temp_var.standard_name = 'air_temperature'\n",
    "temp_var.coordinates = 'lon-lat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some global attributes\n",
    "\n",
    "The [CF Metadata Conventions](https://cfconventions.org/cf-conventions/cf-conventions.html#_overview) recommends a set of global attributes to \"provide human readable documentation of the file contents\":\n",
    "- title\n",
    "- history\n",
    "- institution\n",
    "- source\n",
    "- references\n",
    "- comment\n",
    "\n",
    "Add each of the above to your `Dataset` instance. Here are some suggested values (but you can say whatever you like):\n",
    "- title: Air Temperature forecasts for `<gridID>`\n",
    "- history: File created on: `<YYYY-MM-DD>`\n",
    "- institution: NCAS-ISC\n",
    "- source: NOAA Weather API Service\n",
    "- references: https://www.weather.gov/documentation/services-web-api\n",
    "- comment: The ISC course is teaching me about Python and NetCDF!\n",
    "\n",
    "You can add any other global attributes that you wish to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.title = f'Air Temperature forecasts for {gridID}'\n",
    "dataset.history = f'File created on: {dt.now().strftime(\"%Y-%m-%d\")}'\n",
    "dataset.institution = 'NCAS-ISC'\n",
    "dataset.source = 'NOAA Weather API Service'\n",
    "dataset.references = 'https://www.weather.gov/documentation/services-web-api'\n",
    "dataset.comment = 'This course is OK!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, close the `Dataset` to save the file\n",
    "\n",
    "Save your NetCDF file by closing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check it is there using `os.path.isfile(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Move the file to your MY_DATA_DIR so it gets copied to the GROUP_DATA_DIR\n",
    "\n",
    "Since we cannot write directly to the `GROUP_DATA_DIR`, move the file from your `HOME_DIR` to your `MY_DATA_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename(outfile, f\"{MY_DATA_DIR}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Find all the NetCDF files written during this exercise\n",
    "\n",
    "To find all the `.nc` files in a group workspace, we will use the glob module in Python.\n",
    "Glob let's us find all files matching a pattern, in our case:\n",
    "\n",
    "`{GROUP_DATA_DIR}/*.nc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Can you use glob to make a list of file paths of all NetCDF files in the\n",
    "group workspace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gws/pw/j07/workshop/weather-api-data/TOP-dlloyd-temps.nc', '/gws/pw/j07/workshop/weather-api-data/LIX-train018-temps.nc', '/gws/pw/j07/workshop/weather-api-data/GLD-train026-temps.nc', '/gws/pw/j07/workshop/weather-api-data/BOI-maia_jas-temps.nc', '/gws/pw/j07/workshop/weather-api-data/ICT-train031-temps.nc', '/gws/pw/j07/workshop/weather-api-data/KEY-train067-temps.nc']\n"
     ]
    }
   ],
   "source": [
    "#filepaths = glob(f\"{GROUP_DATA_DIR}/*.nc\")\n",
    "print(filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Create a time-series graph of all the forecasts\n",
    "\n",
    "Now that we have a list of NetCDF file paths, we can open them and extract their data.\n",
    "\n",
    "To start, let us make the a plot using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import num2date\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a subplots figure with figure and axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Can you set the x-axis locator (ticks) using dates class from matplotlib?\n",
    "- set the major locator to days.\n",
    "- set the minor locator to every 6 hours.\n",
    "- set the x-axis formatter to Day-Month for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# In the matplotlib.dates module, as mdates, look at the DayLocator and HourLocator.\n",
    "fmt_day = ...\n",
    "fmt_six_hours = ...\n",
    "\n",
    "ax.xaxis.set_major_locator(fmt_day)\n",
    "ax.xaxis.set_minor_locator(fmt_six_hours)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Label the axis, `ax`, on the plot:\n",
    "- label the x-axis as `Date`\n",
    "- label the y-axis as `Air Temperature / K`\n",
    "- set a title on your plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Open each NetCDF file and extract the `temp`, `time`, `lat` and `lon` variables from the file. Then use the matplotlib `plot_date` function to plot the graph.\n",
    "\n",
    "- set the label of plot to the `<lat>, <lon>` coordinates attribute of the `temp` variable.\n",
    "\n",
    "Replace the elipses with your plotting, the `for` loop works through all the shared NetCDF files in the workspace, where `f` is the file path and `filepaths` is a list of data files.\n",
    "\n",
    "If you need help, look at the 'Plotting data with matplotlib' slide in the [logging data from serial ports](https://github.com/ncasuk/ncas-isc/raw/68abbfd3a573e576c32fc127fafc874bfff98b1e/python/presentations/logging-data-from-serial-ports/LDFSP_Slides.pdf) presentation.\n",
    "\n",
    "Plot a line graph using matplotlib: \n",
    "\n",
    "- you will need to set the marker to `-` otherwise you will get a scatter graph.\n",
    "- set the label of the plot to a string: `<lat>, <lon>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for f in filepaths:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, show the plot with a legend, you might want to enable tight layout,\n",
    "and save the plot to your `MY_DATA_DIR` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the graph to a PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{MY_DATA_DIR}/{gridID}-{USER}-temps.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
